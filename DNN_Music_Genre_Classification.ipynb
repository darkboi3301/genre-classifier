{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN Music Genre Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW5zxykNJuMA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "48d28db7-f051-4756-8574-fd148425845e"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_YiqW33IQ5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXl6P0UMJR83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
        "    \n",
        "    \n",
        "    m = X.shape[1]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "   \n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[:, permutation]\n",
        "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
        "\n",
        "   \n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYuHKaBHJdpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y\n",
        "\n",
        "\n",
        "def predict(X, parameters):\n",
        "    \n",
        "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
        "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
        "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
        "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
        "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
        "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
        "    \n",
        "    params = {\"W1\": W1,\n",
        "              \"b1\": b1,\n",
        "              \"W2\": W2,\n",
        "              \"b2\": b2,\n",
        "              \"W3\": W3,\n",
        "              \"b3\": b3}\n",
        "    \n",
        "    x = tf.placeholder(\"float\", [25, 1])\n",
        "    \n",
        "    z3 = forward_propagation_for_predict(x, params)\n",
        "    p = tf.argmax(z3)\n",
        "    \n",
        "    sess = tf.Session()\n",
        "    prediction = sess.run(p, feed_dict = {x: X})\n",
        "        \n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9bN1c19JepO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagation_for_predict(X, parameters):\n",
        "    \n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3'] \n",
        "                                                           \n",
        "    Z1 = tf.add(tf.matmul(W1, X), b1)                     \n",
        "    A1 = tf.nn.relu(Z1)                                    \n",
        "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     \n",
        "    A2 = tf.nn.relu(Z2)                                   \n",
        "    Z3 = tf.add(tf.matmul(W3, A2), b3)                    \n",
        "    \n",
        "    return Z3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BSTUmVgKEtP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "3d54e35d-8af3-4497-dc7d-ed3fb0f12a2b"
      },
      "source": [
        "# Loading the dataset\n",
        "#X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "#data = pd.read_csv('data.csv')\n",
        "features = pd.read_csv('features_3_sec.csv')\n",
        "#data = data.drop(['filename'],axis=1)\n",
        "features = features.drop('filename',axis=1)\n",
        "np.random.seed(10)\n",
        "permut = list(np.random.permutation(9900))\n",
        "\n",
        "genre_list = features.iloc[:, -1]\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(genre_list)\n",
        "onehotencode = OneHotEncoder(sparse=False)\n",
        "#print(len(yl))\n",
        "y = y.reshape(len(y), 1)\n",
        "y = onehotencode.fit_transform(y).T\n",
        "print(y.shape)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(np.array(features.iloc[:, :-1], dtype = float))\n",
        "print(X.shape)\n",
        "X = X[permut,:]\n",
        "y = y[:,permut]\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y.T, test_size=0.2,stratify = y.T\n",
        "                                                   )\n",
        "\n",
        "#print(data.iloc[:,:-1].shape)\n",
        "#x_train = x_train.reshape((25,720))\n",
        "print(x_train.shape)\n",
        "\n",
        "x_train = x_train.T\n",
        "print(x_train.shape)\n",
        "y_train = y_train.T\n",
        "print(y_train.shape)\n",
        "x_test = x_test.T\n",
        "y_test = y_test.T\n",
        "\n",
        "features.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 9990)\n",
            "(9990, 58)\n",
            "(7920, 58)\n",
            "(58, 7920)\n",
            "(10, 7920)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>length</th>\n",
              "      <th>chroma_stft_mean</th>\n",
              "      <th>chroma_stft_var</th>\n",
              "      <th>rms_mean</th>\n",
              "      <th>rms_var</th>\n",
              "      <th>spectral_centroid_mean</th>\n",
              "      <th>spectral_centroid_var</th>\n",
              "      <th>spectral_bandwidth_mean</th>\n",
              "      <th>spectral_bandwidth_var</th>\n",
              "      <th>rolloff_mean</th>\n",
              "      <th>rolloff_var</th>\n",
              "      <th>zero_crossing_rate_mean</th>\n",
              "      <th>zero_crossing_rate_var</th>\n",
              "      <th>harmony_mean</th>\n",
              "      <th>harmony_var</th>\n",
              "      <th>perceptr_mean</th>\n",
              "      <th>perceptr_var</th>\n",
              "      <th>tempo</th>\n",
              "      <th>mfcc1_mean</th>\n",
              "      <th>mfcc1_var</th>\n",
              "      <th>mfcc2_mean</th>\n",
              "      <th>mfcc2_var</th>\n",
              "      <th>mfcc3_mean</th>\n",
              "      <th>mfcc3_var</th>\n",
              "      <th>mfcc4_mean</th>\n",
              "      <th>mfcc4_var</th>\n",
              "      <th>mfcc5_mean</th>\n",
              "      <th>mfcc5_var</th>\n",
              "      <th>mfcc6_mean</th>\n",
              "      <th>mfcc6_var</th>\n",
              "      <th>mfcc7_mean</th>\n",
              "      <th>mfcc7_var</th>\n",
              "      <th>mfcc8_mean</th>\n",
              "      <th>mfcc8_var</th>\n",
              "      <th>mfcc9_mean</th>\n",
              "      <th>mfcc9_var</th>\n",
              "      <th>mfcc10_mean</th>\n",
              "      <th>mfcc10_var</th>\n",
              "      <th>mfcc11_mean</th>\n",
              "      <th>mfcc11_var</th>\n",
              "      <th>mfcc12_mean</th>\n",
              "      <th>mfcc12_var</th>\n",
              "      <th>mfcc13_mean</th>\n",
              "      <th>mfcc13_var</th>\n",
              "      <th>mfcc14_mean</th>\n",
              "      <th>mfcc14_var</th>\n",
              "      <th>mfcc15_mean</th>\n",
              "      <th>mfcc15_var</th>\n",
              "      <th>mfcc16_mean</th>\n",
              "      <th>mfcc16_var</th>\n",
              "      <th>mfcc17_mean</th>\n",
              "      <th>mfcc17_var</th>\n",
              "      <th>mfcc18_mean</th>\n",
              "      <th>mfcc18_var</th>\n",
              "      <th>mfcc19_mean</th>\n",
              "      <th>mfcc19_var</th>\n",
              "      <th>mfcc20_mean</th>\n",
              "      <th>mfcc20_var</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>66149</td>\n",
              "      <td>0.335406</td>\n",
              "      <td>0.091048</td>\n",
              "      <td>0.130405</td>\n",
              "      <td>0.003521</td>\n",
              "      <td>1773.065032</td>\n",
              "      <td>167541.630869</td>\n",
              "      <td>1972.744388</td>\n",
              "      <td>117335.771563</td>\n",
              "      <td>3714.560359</td>\n",
              "      <td>1.080790e+06</td>\n",
              "      <td>0.081851</td>\n",
              "      <td>0.000558</td>\n",
              "      <td>-0.000078</td>\n",
              "      <td>0.008354</td>\n",
              "      <td>-0.000068</td>\n",
              "      <td>0.005535</td>\n",
              "      <td>129.199219</td>\n",
              "      <td>-118.627914</td>\n",
              "      <td>2440.286621</td>\n",
              "      <td>125.083626</td>\n",
              "      <td>260.956909</td>\n",
              "      <td>-23.443724</td>\n",
              "      <td>364.081726</td>\n",
              "      <td>41.321484</td>\n",
              "      <td>181.694855</td>\n",
              "      <td>-5.976108</td>\n",
              "      <td>152.963135</td>\n",
              "      <td>20.115141</td>\n",
              "      <td>75.652298</td>\n",
              "      <td>-16.045410</td>\n",
              "      <td>40.227104</td>\n",
              "      <td>17.855198</td>\n",
              "      <td>84.320282</td>\n",
              "      <td>-14.633434</td>\n",
              "      <td>83.437233</td>\n",
              "      <td>10.270527</td>\n",
              "      <td>97.001335</td>\n",
              "      <td>-9.708279</td>\n",
              "      <td>66.669891</td>\n",
              "      <td>10.183875</td>\n",
              "      <td>45.103611</td>\n",
              "      <td>-4.681614</td>\n",
              "      <td>34.169498</td>\n",
              "      <td>8.417439</td>\n",
              "      <td>48.269444</td>\n",
              "      <td>-7.233477</td>\n",
              "      <td>42.770947</td>\n",
              "      <td>-2.853603</td>\n",
              "      <td>39.687145</td>\n",
              "      <td>-3.241280</td>\n",
              "      <td>36.488243</td>\n",
              "      <td>0.722209</td>\n",
              "      <td>38.099152</td>\n",
              "      <td>-5.050335</td>\n",
              "      <td>33.618073</td>\n",
              "      <td>-0.243027</td>\n",
              "      <td>43.771767</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>66149</td>\n",
              "      <td>0.343065</td>\n",
              "      <td>0.086147</td>\n",
              "      <td>0.112699</td>\n",
              "      <td>0.001450</td>\n",
              "      <td>1816.693777</td>\n",
              "      <td>90525.690866</td>\n",
              "      <td>2010.051501</td>\n",
              "      <td>65671.875673</td>\n",
              "      <td>3869.682242</td>\n",
              "      <td>6.722448e+05</td>\n",
              "      <td>0.087173</td>\n",
              "      <td>0.001030</td>\n",
              "      <td>-0.000099</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>-0.000103</td>\n",
              "      <td>0.004854</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-125.590706</td>\n",
              "      <td>2038.344238</td>\n",
              "      <td>122.421227</td>\n",
              "      <td>216.774185</td>\n",
              "      <td>-20.718019</td>\n",
              "      <td>231.979767</td>\n",
              "      <td>50.128387</td>\n",
              "      <td>142.700409</td>\n",
              "      <td>-11.333302</td>\n",
              "      <td>139.243118</td>\n",
              "      <td>21.385401</td>\n",
              "      <td>77.817947</td>\n",
              "      <td>-15.960796</td>\n",
              "      <td>97.364029</td>\n",
              "      <td>19.454103</td>\n",
              "      <td>57.948093</td>\n",
              "      <td>-12.465918</td>\n",
              "      <td>68.271523</td>\n",
              "      <td>17.898169</td>\n",
              "      <td>56.222176</td>\n",
              "      <td>-11.732554</td>\n",
              "      <td>54.373909</td>\n",
              "      <td>8.145000</td>\n",
              "      <td>40.662876</td>\n",
              "      <td>-7.717751</td>\n",
              "      <td>30.808521</td>\n",
              "      <td>8.397150</td>\n",
              "      <td>48.784225</td>\n",
              "      <td>-8.300493</td>\n",
              "      <td>68.584824</td>\n",
              "      <td>4.074709</td>\n",
              "      <td>64.748276</td>\n",
              "      <td>-6.055294</td>\n",
              "      <td>40.677654</td>\n",
              "      <td>0.159015</td>\n",
              "      <td>51.264091</td>\n",
              "      <td>-2.837699</td>\n",
              "      <td>97.030830</td>\n",
              "      <td>5.784063</td>\n",
              "      <td>59.943081</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>66149</td>\n",
              "      <td>0.346815</td>\n",
              "      <td>0.092243</td>\n",
              "      <td>0.132003</td>\n",
              "      <td>0.004620</td>\n",
              "      <td>1788.539719</td>\n",
              "      <td>111407.437613</td>\n",
              "      <td>2084.565132</td>\n",
              "      <td>75124.921716</td>\n",
              "      <td>3997.639160</td>\n",
              "      <td>7.907127e+05</td>\n",
              "      <td>0.071383</td>\n",
              "      <td>0.000425</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>0.012476</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.004357</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-132.441940</td>\n",
              "      <td>3798.532227</td>\n",
              "      <td>115.085175</td>\n",
              "      <td>257.321289</td>\n",
              "      <td>-14.811666</td>\n",
              "      <td>192.448074</td>\n",
              "      <td>50.189293</td>\n",
              "      <td>144.166031</td>\n",
              "      <td>-0.680819</td>\n",
              "      <td>128.376892</td>\n",
              "      <td>24.650375</td>\n",
              "      <td>66.371170</td>\n",
              "      <td>-13.506104</td>\n",
              "      <td>89.319336</td>\n",
              "      <td>15.643386</td>\n",
              "      <td>55.253967</td>\n",
              "      <td>-13.216637</td>\n",
              "      <td>120.308784</td>\n",
              "      <td>10.406025</td>\n",
              "      <td>35.757862</td>\n",
              "      <td>-7.991465</td>\n",
              "      <td>47.911613</td>\n",
              "      <td>11.853963</td>\n",
              "      <td>36.569931</td>\n",
              "      <td>-4.677677</td>\n",
              "      <td>40.725075</td>\n",
              "      <td>6.571110</td>\n",
              "      <td>30.686846</td>\n",
              "      <td>-2.424750</td>\n",
              "      <td>50.313499</td>\n",
              "      <td>4.806280</td>\n",
              "      <td>67.336563</td>\n",
              "      <td>-1.768610</td>\n",
              "      <td>28.348579</td>\n",
              "      <td>2.378768</td>\n",
              "      <td>45.717648</td>\n",
              "      <td>-1.938424</td>\n",
              "      <td>53.050835</td>\n",
              "      <td>2.517375</td>\n",
              "      <td>33.105122</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>66149</td>\n",
              "      <td>0.363639</td>\n",
              "      <td>0.086856</td>\n",
              "      <td>0.132565</td>\n",
              "      <td>0.002448</td>\n",
              "      <td>1655.289045</td>\n",
              "      <td>111952.284517</td>\n",
              "      <td>1960.039988</td>\n",
              "      <td>82913.639269</td>\n",
              "      <td>3568.300218</td>\n",
              "      <td>9.216524e+05</td>\n",
              "      <td>0.069426</td>\n",
              "      <td>0.000304</td>\n",
              "      <td>-0.000014</td>\n",
              "      <td>0.008318</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.005927</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-118.231087</td>\n",
              "      <td>2508.781006</td>\n",
              "      <td>132.116501</td>\n",
              "      <td>332.650574</td>\n",
              "      <td>-18.758335</td>\n",
              "      <td>109.357529</td>\n",
              "      <td>39.769306</td>\n",
              "      <td>184.693344</td>\n",
              "      <td>-13.260426</td>\n",
              "      <td>144.398224</td>\n",
              "      <td>20.468134</td>\n",
              "      <td>122.516464</td>\n",
              "      <td>-14.563448</td>\n",
              "      <td>68.937332</td>\n",
              "      <td>18.745104</td>\n",
              "      <td>74.748886</td>\n",
              "      <td>-13.755463</td>\n",
              "      <td>73.868576</td>\n",
              "      <td>12.993759</td>\n",
              "      <td>41.549564</td>\n",
              "      <td>-12.648887</td>\n",
              "      <td>58.540478</td>\n",
              "      <td>10.389314</td>\n",
              "      <td>39.102024</td>\n",
              "      <td>-4.362739</td>\n",
              "      <td>60.714748</td>\n",
              "      <td>9.156193</td>\n",
              "      <td>40.411537</td>\n",
              "      <td>-9.889441</td>\n",
              "      <td>44.666325</td>\n",
              "      <td>-1.359111</td>\n",
              "      <td>47.739452</td>\n",
              "      <td>-3.841155</td>\n",
              "      <td>28.337118</td>\n",
              "      <td>1.218588</td>\n",
              "      <td>34.770935</td>\n",
              "      <td>-3.580352</td>\n",
              "      <td>50.836224</td>\n",
              "      <td>3.630866</td>\n",
              "      <td>32.023678</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>66149</td>\n",
              "      <td>0.335579</td>\n",
              "      <td>0.088129</td>\n",
              "      <td>0.143289</td>\n",
              "      <td>0.001701</td>\n",
              "      <td>1630.656199</td>\n",
              "      <td>79667.267654</td>\n",
              "      <td>1948.503884</td>\n",
              "      <td>60204.020268</td>\n",
              "      <td>3469.992864</td>\n",
              "      <td>6.102111e+05</td>\n",
              "      <td>0.070095</td>\n",
              "      <td>0.000289</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.009634</td>\n",
              "      <td>-0.000106</td>\n",
              "      <td>0.005833</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-105.968376</td>\n",
              "      <td>2118.919922</td>\n",
              "      <td>134.643646</td>\n",
              "      <td>219.562622</td>\n",
              "      <td>-19.961748</td>\n",
              "      <td>171.878754</td>\n",
              "      <td>40.171753</td>\n",
              "      <td>103.120712</td>\n",
              "      <td>-14.271939</td>\n",
              "      <td>102.651230</td>\n",
              "      <td>18.734617</td>\n",
              "      <td>79.070000</td>\n",
              "      <td>-15.619381</td>\n",
              "      <td>48.510284</td>\n",
              "      <td>19.207966</td>\n",
              "      <td>53.642956</td>\n",
              "      <td>-18.274683</td>\n",
              "      <td>95.300995</td>\n",
              "      <td>14.316693</td>\n",
              "      <td>58.821163</td>\n",
              "      <td>-5.792194</td>\n",
              "      <td>55.030254</td>\n",
              "      <td>17.045437</td>\n",
              "      <td>43.229939</td>\n",
              "      <td>-5.681399</td>\n",
              "      <td>46.515259</td>\n",
              "      <td>5.705521</td>\n",
              "      <td>24.956211</td>\n",
              "      <td>-7.986080</td>\n",
              "      <td>39.816933</td>\n",
              "      <td>2.092937</td>\n",
              "      <td>30.336359</td>\n",
              "      <td>0.664582</td>\n",
              "      <td>45.880913</td>\n",
              "      <td>1.689446</td>\n",
              "      <td>51.363583</td>\n",
              "      <td>-3.392489</td>\n",
              "      <td>26.738789</td>\n",
              "      <td>0.536961</td>\n",
              "      <td>29.146694</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   length  chroma_stft_mean  chroma_stft_var  ...  mfcc20_mean  mfcc20_var  label\n",
              "0   66149          0.335406         0.091048  ...    -0.243027   43.771767  blues\n",
              "1   66149          0.343065         0.086147  ...     5.784063   59.943081  blues\n",
              "2   66149          0.346815         0.092243  ...     2.517375   33.105122  blues\n",
              "3   66149          0.363639         0.086856  ...     3.630866   32.023678  blues\n",
              "4   66149          0.335579         0.088129  ...     0.536961   29.146694  blues\n",
              "\n",
              "[5 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqqLZi5hLIVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "    \n",
        "    X = tf.placeholder(tf.float32,shape = (n_x,None))\n",
        "    Y =  tf.placeholder(tf.float32,shape = (n_y,None))\n",
        "   \n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEJYRW6YLU6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def initialize_parameters():\n",
        "    \n",
        "    \n",
        "    tf.set_random_seed(1)                  \n",
        "        \n",
        "    W1 = tf.get_variable(\"W1\",[128,58],initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b1 = tf.get_variable(\"b1\",[128,1],initializer = tf.zeros_initializer())\n",
        "    W2 = tf.get_variable(\"W2\",[64,128],initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b2 = tf.get_variable(\"b2\",[64,1],initializer = tf.zeros_initializer())\n",
        "    W3 = tf.get_variable(\"W3\",[10,64],initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b3 = tf.get_variable(\"b3\",[10,1],initializer = tf.zeros_initializer())\n",
        " \n",
        "    print(W1)\n",
        "   \n",
        "\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2,\n",
        "                  \"W3\": W3,\n",
        "                  \"b3\": b3\n",
        "                }\n",
        "    \n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6JI8DdkLhqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    \n",
        "    tf.set_random_seed(2)\n",
        "    \n",
        "    \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "   \n",
        "    \n",
        "    \n",
        "    Z1 = tf.add(tf.matmul(W1, X), b1)                    \n",
        "    A1 = tf.nn.relu(Z1) \n",
        "    A1 = tf.nn.dropout(A1,keep_prob = 0.9) \n",
        "\n",
        "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     \n",
        "    A2 = tf.nn.relu(Z2)  \n",
        "    A2 = tf.nn.dropout(A2,keep_prob=0.9)\n",
        "                    \n",
        "    Z3 = tf.add(tf.matmul(W3, A2), b3)  \n",
        "   \n",
        "    \n",
        "    return Z3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-KddtvLL0Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(Z3, Y):\n",
        "   \n",
        "    logits = tf.transpose(Z3)\n",
        "    labels = tf.transpose(Y)\n",
        "    \n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits,labels =labels))\n",
        "   \n",
        "    return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl3yBGWvMCHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.001,\n",
        "          num_epochs = 250, minibatch_size = 64, print_cost = True):\n",
        "   \n",
        "    \n",
        "    ops.reset_default_graph()                         \n",
        "    tf.set_random_seed(1)                             \n",
        "    seed = 3                                          \n",
        "    (n_x, m) = X_train.shape                         \n",
        "    n_y = Y_train.shape[0]                           \n",
        "    costs = []                                       \n",
        "    \n",
        "    \n",
        "    X, Y = create_placeholders(n_x,n_y)\n",
        "    \n",
        "    parameters = initialize_parameters()\n",
        "    \n",
        "    Z3= forward_propagation(X,parameters)\n",
        "   \n",
        "    cost = compute_cost(Z3,Y)\n",
        "    \n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate,beta1=0.9,beta2 = 0.999,epsilon = 1e-08).minimize(cost)\n",
        "   \n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "      sess.run(init)\n",
        "        \n",
        "        \n",
        "      for epoch in range(num_epochs):\n",
        "\n",
        "        epoch_cost = 0.                       \n",
        "        num_minibatches = int(m / minibatch_size) \n",
        "        seed = seed + 1\n",
        "        minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
        "\n",
        "        for minibatch in minibatches:\n",
        "\n",
        "               \n",
        "          (minibatch_X, minibatch_Y) = minibatch\n",
        "                \n",
        "               \n",
        "          _ , minibatch_cost = sess.run([optimizer,cost],feed_dict = {X:minibatch_X,Y:minibatch_Y}\n",
        "                                             )\n",
        "               \n",
        "                \n",
        "          epoch_cost += minibatch_cost / minibatch_size\n",
        "\n",
        "           \n",
        "        if print_cost == True and epoch % 10 == 0:\n",
        "            print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "                \n",
        "        if print_cost == True and epoch % 5 == 0:\n",
        "            costs.append(epoch_cost)\n",
        "                \n",
        "        \n",
        "      plt.plot(np.squeeze(costs))\n",
        "      plt.ylabel('cost')\n",
        "      plt.xlabel('iterations (per fives)')\n",
        "      plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "      plt.show()\n",
        "\n",
        "        \n",
        "      parameters = sess.run(parameters)\n",
        "      print (\"Parameters have been trained!\")\n",
        "\n",
        "        \n",
        "      correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
        "        \n",
        "       \n",
        "      accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "      print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
        "      print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
        "        \n",
        "      return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKu0lOCWMiRI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "outputId": "8d395793-ab03-4598-9722-5f611aa92e3d"
      },
      "source": [
        "parameters = model(x_train, y_train, x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'W1:0' shape=(128, 58) dtype=float32_ref>\n",
            "Cost after epoch 0: 2.997249\n",
            "Cost after epoch 10: 0.924625\n",
            "Cost after epoch 20: 0.603617\n",
            "Cost after epoch 30: 0.445837\n",
            "Cost after epoch 40: 0.350704\n",
            "Cost after epoch 50: 0.279318\n",
            "Cost after epoch 60: 0.239470\n",
            "Cost after epoch 70: 0.198769\n",
            "Cost after epoch 80: 0.183959\n",
            "Cost after epoch 90: 0.183107\n",
            "Cost after epoch 100: 0.161355\n",
            "Cost after epoch 110: 0.139136\n",
            "Cost after epoch 120: 0.144801\n",
            "Cost after epoch 130: 0.135137\n",
            "Cost after epoch 140: 0.117865\n",
            "Cost after epoch 150: 0.117843\n",
            "Cost after epoch 160: 0.107789\n",
            "Cost after epoch 170: 0.112263\n",
            "Cost after epoch 180: 0.104715\n",
            "Cost after epoch 190: 0.098914\n",
            "Cost after epoch 200: 0.095924\n",
            "Cost after epoch 210: 0.091847\n",
            "Cost after epoch 220: 0.081197\n",
            "Cost after epoch 230: 0.093912\n",
            "Cost after epoch 240: 0.092662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters have been trained!\n",
            "Train Accuracy: 0.98724747\n",
            "Test Accuracy: 0.8848485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03ac5LsnNYSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}